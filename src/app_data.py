"""Data loading utilities for streamlined Streamlit app (v2).

Design goals:
- Keep app experience fast: all heavy preprocessing should be precomputed.
- Provide mineral-specific label & prediction loading with graceful fallback.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict, Tuple, Optional
import numpy as np
import joblib
import geopandas as gpd
import json

ProcessedRoot = Path("data/processed")


def _ensure_setup():
    # If critical artifact missing, user likely has to run setup manually.
    if not (ProcessedRoot / "grid_gdf.joblib").exists():
        raise FileNotFoundError("Missing processed data. Run setup.py to generate artifacts.")


def load_common() -> Tuple[gpd.GeoDataFrame, Dict[str, np.ndarray], Dict[str, list]]:
    _ensure_setup()
    grid = joblib.load(ProcessedRoot / "grid_gdf.joblib")
    features = {}
    feature_names = {}
    for f in ProcessedRoot.glob("X_*.npy"):
        key = f.stem
        features[key] = np.load(f)
        # feature_names_geo.json naming pattern used previously
        suffix = key.split("_", 1)[1]
        meta = ProcessedRoot / f"feature_names_{suffix}.json"
        if meta.exists():
            try:
                feature_names[key] = json.loads(meta.read_text())
            except Exception:
                feature_names[key] = [key]
        else:
            if key == "X_coords":
                feature_names[key] = ["lon", "lat"]
            else:
                feature_names[key] = [key]
    return grid, features, feature_names


def mineral_code(label: str) -> str:
    return label.lower().strip()


def load_mineral_labels(mineral: str) -> np.ndarray:
    m = mineral_code(mineral)
    cand = [ProcessedRoot / f"y_labels_{m}.npy", ProcessedRoot / "y_labels_crit.npy", ProcessedRoot / "y_labels.npy"]
    for p in cand:
        if p.exists():
            return np.load(p)
    raise FileNotFoundError("No label array found.")


def load_mineral_predictions(mineral: str) -> Dict[str, np.ndarray]:
    m = mineral_code(mineral)
    out: Dict[str, np.ndarray] = {}
    mapping = {
        "rf": f"rf_probs_{m}.npy",
        "bayes_mean": f"bayes_mean_{m}.npy",
        "bayes_std": f"bayes_std_{m}.npy",
    }
    for k, fname in mapping.items():
        path = ProcessedRoot / fname
        if path.exists():
            try:
                out[k] = np.load(path)
            except Exception:
                pass
    return out


def load_rf_importances(mineral: str):
    m = mineral_code(mineral)
    path = ProcessedRoot / f"rf_importances_{m}.csv"
    if path.exists():
        try:
            import pandas as _pd
            return _pd.read_csv(path)
        except Exception:
            return None
    return None


def load_targets(mineral: str) -> Optional[gpd.GeoDataFrame]:
    m = mineral_code(mineral)
    # Priority order:
    # 1. Mineral-specific shortlist CSV (targets_<m>.csv) generated by precompute script
    # 2. Mineral-specific geopackage
    # 3. Generic targets.gpkg
    csv_path = ProcessedRoot / f"targets_{m}.csv"
    if csv_path.exists():
        try:
            import pandas as _pd
            df = _pd.read_csv(csv_path)
            if {"lon", "lat"}.issubset(df.columns):
                gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df["lon"], df["lat"]), crs="EPSG:4326")
                return gdf
        except Exception:
            pass
    for fname in [f"targets_{m}.gpkg", "targets.gpkg"]:
        path = ProcessedRoot / fname
        if path.exists():
            try:
                return gpd.read_file(path)
            except Exception:
                return None
    return None
